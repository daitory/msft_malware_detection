import pandas as pd
import numpy  as np 
import io
import multicore
import time

start=time.time()
dataframe=pd.read_csv(filepath_or_buffer="D:\\Documents\\Data Science Certificate\\group_assignment\\microsoft-malware-prediction\\train.csv",sep=",",low_memory=False)
#data_project.info()
end=time.time()
print((end-start)/60)
print("time elapsed :  ",(end-start)/60)
start=time.time()

startingMemoryUsage = dataframe.memory_usage().sum() / 1024**2

print('Dataframe was {:.2f} MB'.format(startingMemoryUsage))

for column in dataframe.columns:
    columnDataType = dataframe[column].dtype

    if columnDataType != object:
        columnMin = dataframe[column].min()
        columnMax = dataframe[column].max()

        if str(columnDataType)[:3] == 'int':
            if columnMin > np.iinfo(np.int8).min and columnMax < np.iinfo(np.int8).max:
                dataframe[column] = dataframe[column].astype(np.int8)
            elif columnMin > np.iinfo(np.int16).min and columnMax < np.iinfo(np.int16).max:
                dataframe[column] = dataframe[column].astype(np.int16)
            elif columnMin > np.iinfo(np.int32).min and columnMax < np.iinfo(np.int32).max:
                dataframe[column] = dataframe[column].astype(np.int32)
            elif columnMin > np.iinfo(np.int64).min and columnMax < np.iinfo(np.int64).max:
                dataframe[column] = dataframe[column].astype(np.int64)  
        else:
            if columnMin > np.finfo(np.float16).min and columnMax < np.finfo(np.float16).max:
                dataframe[column] = dataframe[column].astype(np.float16)
            elif columnMin > np.finfo(np.float32).min and columnMax < np.finfo(np.float32).max:
                dataframe[column] = dataframe[column].astype(np.float32)
            else:
                dataframe[column] = dataframe[column].astype(np.float64)
    else:
        dataframe[column] = dataframe[column].astype('category')

endingingMemoryUsage = dataframe.memory_usage().sum() / 1024**2

print('Dataframe is now: {:.2f} MB'.format(endingingMemoryUsage))

end=time.time()
print((end-start)/60)
print("time elapsed :  ",(end-start)/60)


###############################################################################################################################################################################
#                                                                   DATA CLEANING 
###############################################################################################################################################################################



data_project=dataframe
print("Quantity of computers with a malware infection %7.1f " % data_project['HasDetections'].sum())
print("Quantity  of computers analyzed %7.1f" % data_project['HasDetections'].count())
print("Percentage of problems of the overall machines analyzed %1.3f " % (data_project['HasDetections'].sum()/data_project['HasDetections'].count()))

print(np.sort(data_project.isnull().sum()/data_project.shape[0]))

col_drop=[data_project.columns[i] for i in range(0,data_project.shape[1])  if((data_project.iloc[:,i].isnull().sum()/data_project.shape[0])>=0.3)  ]
print("Columns that are going to be removed",col_drop)

data_project1=data_project.drop(col_drop,axis=1)
data_project1.head(5)


#FILLING VARIABLES  - AS I CORROBORATE WE CAN ERRASE THE RAM PROBLEMS (AS WE COUNT WITH 8.9MM dataset , if we do that we can eliminate the combination of RAM  and processor core count missing)
data_project1[['Census_TotalPhysicalRAM','Census_ProcessorCoreCount','Processor','Census_InternalPrimaryDiagonalDisplaySizeInInches','AVProductsInstalled','Platform']].info()
print(data_project1[['Census_TotalPhysicalRAM','Census_ProcessorCoreCount','Processor','Census_InternalPrimaryDiagonalDisplaySizeInInches','AVProductsInstalled','Platform']].isnull().sum())
print(data_project1[['Census_TotalPhysicalRAM','Census_ProcessorCoreCount','Processor','Census_InternalPrimaryDiagonalDisplaySizeInInches','AVProductsInstalled','Platform']].isnull().sum()/data_project1.shape[0])

# THIS OPTION WAS NOT USED (THE FILLED OF MEMORY)
# THERE IS A CHANCE TO FILL THE AMOUNT OF MEMORY BASE IN : THOSE ARM (ARE TABLETS SO THEY COULD BE BOUND TO THE MORE COMMON TABLET MEMORY, IN THE CASE OF 64 BITS COULD BE ATTACHED TO THE RAM OVER 4 GB INCLUSIVE WITH MORE QUANTITY THE SAME AS X86 (32BITS ) WITH LESS THAN 4 GB - MORE COMMON DATA)

data_project1['Census_TotalPhysicalRAM'][data_project1['Census_TotalPhysicalRAM'].isnull()]
print("almost all the processor core count null are associated with total phisical RAM null: %i " % (data_project1['Census_ProcessorCoreCount'][data_project1['Census_TotalPhysicalRAM'].isnull() ].isnull().sum()))
#this is going to erase the memory missings (there are so a lot of filled with memory so we are just losing 1% of the data with this cleaning)
data_project2=data_project1[data_project1['Census_TotalPhysicalRAM'].isnull()==False] #NAN FILTER FOR MEMORY
print(data_project2[['Census_TotalPhysicalRAM','Census_ProcessorCoreCount','Processor','Census_InternalPrimaryDiagonalDisplaySizeInInches','AVProductsInstalled','Platform']].isnull().sum())
print(data_project2[['Census_TotalPhysicalRAM','Census_ProcessorCoreCount','Processor','Census_InternalPrimaryDiagonalDisplaySizeInInches','AVProductsInstalled','Platform']].isnull().sum()/data_project2.shape[0])
data_project2['Processor'][data_project2['Census_ProcessorCoreCount'].isnull()].unique()


start=time.time()
value_64=np.array((data_project2['Census_ProcessorCoreCount'][(data_project2['Census_ProcessorCoreCount']>4)  * (data_project2['Processor']=='x64') ])).mean()
value_32=np.array((data_project2['Census_ProcessorCoreCount'][(data_project2['Census_ProcessorCoreCount']<=4)  * (data_project2['Processor']=='x86') ])).mean()
value_arm64=np.array((data_project2['Census_ProcessorCoreCount'][ (data_project2['Processor']=='arm64') *  (data_project2['Census_ProcessorCoreCount'].isnull()==False) ])).mean() 

data_project2['ProcessorCoreCount_4missing']=data_project2[['Processor','Census_ProcessorCoreCount']].apply(lambda x: value_64 if  (x.loc['Processor']=='x64') else ( value_32  if ((x.loc['Processor']=='x86') ) else (value_arm64 ) ),axis=1)
end=time.time()

print("elapsed time",(end-start)/60)
#I have to check the results that comes out from the preceding lambda 


data_project2['filled_ProcessorCoreCount']=data_project2[['ProcessorCoreCount_4missing','Census_ProcessorCoreCount']].apply(lambda x: x.loc['ProcessorCoreCount_4missing'] if  (np.isnan(x.loc['Census_ProcessorCoreCount'])) else x.loc['Census_ProcessorCoreCount'],axis=1)

data_project2['filled_ProcessorCoreCount'].isnull().sum()

#THERE IS NO NAN's in this variable
#####################################################################################################################################
# PRIMARY DISK TYPE NAME
#THE PRIMARY DISK WOULD BE IMPORTANT ALSO
data_project2['Census_PrimaryDiskTypeName'] = data_project2['Census_PrimaryDiskTypeName'].replace('Unspecified', 'UNKNOWN')
data_project2['Census_PrimaryDiskTypeName'].fillna('UNKNOWN',inplace=True)
data_project2['Census_PrimaryDiskTypeName'].unique()


data_project2['Census_InternalPrimaryDiagonalDisplaySizeInInches'].unique()

data_project2['Census_ProcessorModelIdentifier']

###################################################################################################################################################################################
#THIS PART IS GOING TO BE USED FOR FILL THE MISSINGS IN THE REST OF THE DATA
data_project2['IsProtected'].unique()
data_project2['GeoNameIdentifier'].unique()
data_project2['AVProductStatesIdentifier'].describe()
data_project2['Census_ProcessorModelIdentifier'].describe()
data_project2['IeVerIdentifier'].describe()

data_project2['CityIdentifier'].fillna(0.0, inplace = True) 
data_project2['OrganizationIdentifier'].fillna(0.0, inplace = True) 
data_project2['GeoNameIdentifier'].fillna(0.0, inplace = True) # the 0.0 means that the data was unknown 
data_project2['IsProtected'].fillna(-1.0, inplace = True) # the -1 means that the data was unknown 
data_project2['IeVerIdentifier'].fillna(0.0, inplace = True) # the 00 means that the data was unknown
data_project2['AVProductStatesIdentifier'].fillna(0.0, inplace = True) # the 00 means that the data was unknown
# data_project2['Census_ProcessorCoreCount'].fillna(0.0, inplace = True)
data_project2['Census_OEMNameIdentifier'].fillna(0.0, inplace = True) 
data_project2['Census_OEMModelIdentifier'].fillna(0.0, inplace = True)
data_project2['Census_ProcessorModelIdentifier'].fillna(0.0, inplace = True)# the 0.0 means that the data was unknown
# data_project2['Census_PrimaryDiskTotalCapacity'].fillna(0.0, inplace = True)
# data_project2['Census_SystemVolumeTotalCapacity'].fillna(0.0, inplace = True)
# data_project2['Census_TotalPhysicalRAM'].fillna(0.0, inplace = True)
data_project2['Census_ChassisTypeName'].fillna("0", inplace = True)
data_project2['Census_InternalPrimaryDiagonalDisplaySizeInInches'].fillna(0.0, inplace = True)
data_project2['Census_InternalPrimaryDisplayResolutionHorizontal'].fillna(0.0, inplace = True)
data_project2['Census_InternalPrimaryDisplayResolutionVertical'].fillna(0.0, inplace = True)
data_project2['Census_OSInstallLanguageIdentifier'].fillna(0.0, inplace = True)
data_project2['Census_FirmwareManufacturerIdentifier'].fillna(0.0, inplace = True)
data_project2['Census_FirmwareVersionIdentifier'].fillna(0.0, inplace = True)
data_project2['Wdft_RegionIdentifier'].fillna(0.0, inplace = True)


############################################################################################################
# CHASIS TYPE NAMES 

data_project2['Census_ChassisTypeName'] = data_project2['Census_ChassisTypeName'].replace(['0', '30', '35', '31', '88', '32', '127', '25', '44', '36', '81', '28', '112', '39', '45', '49', '82', '76'],['UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', 'UNKNOWN'])


############################################################################################################
# Census_PowerPlatformRoleName - Replace null values with "UNKNOWN"

data_project2['Census_PowerPlatformRoleName'].fillna("UNKNOWN", inplace = True) 
data_project2['Census_PowerPlatformRoleName'] = data_project2['Census_PowerPlatformRoleName'].replace("Unspecified", "UNKNOWN")

##############################################################################################################


data_project2['AVProductsInstalled'].fillna(data_project2['AVProductsInstalled'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['AVProductsEnabled'].fillna(data_project2['AVProductsEnabled'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['OsBuildLab'].fillna(data_project2['OsBuildLab'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['SMode'].fillna(data_project2['SMode'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['Firewall'].fillna(data_project2['Firewall'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['Census_ProcessorManufacturerIdentifier'].fillna(data_project2['Census_ProcessorManufacturerIdentifier'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
#data_project2['Census_PrimaryDiskTypeName'].fillna(data_project2['Census_PrimaryDiskTypeName'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['Census_PrimaryDiskTotalCapacity'].fillna(data_project2['Census_PrimaryDiskTotalCapacity'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['Census_SystemVolumeTotalCapacity'].fillna(data_project2['Census_SystemVolumeTotalCapacity'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['Census_HasOpticalDiskDrive'].fillna(data_project2['Census_HasOpticalDiskDrive'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['Census_IsFlightsDisabled'].fillna(data_project2['Census_IsFlightsDisabled'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['Census_IsAlwaysOnAlwaysConnectedCapable'].fillna(data_project2['Census_IsAlwaysOnAlwaysConnectedCapable'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['Census_IsVirtualDevice'].fillna(data_project2['Census_IsVirtualDevice'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['Wdft_IsGamer'].fillna(data_project2['Wdft_IsGamer'].value_counts().sort_values(ascending=False).index[0], inplace = True) 
data_project2['Census_InternalBatteryNumberOfCharges'].fillna(data_project2['Census_InternalBatteryNumberOfCharges'].value_counts().sort_values(ascending=False).index[0], inplace = True) 

#################################################################################################################

data_project2['RtpStateBitfield'].fillna(1.0, inplace = True) 
data_project2['RtpStateBitfield'] = data_project2['RtpStateBitfield'].replace([3.0, 5.0, 7.0, 8.0, 35.0], [1.0, 1.0, 1.0, 1.0, 1.0])


###################################################################################################################
# UacLuaenable - Replace null and non-zero values with 1

data_project2['UacLuaenable'].fillna(1.0, inplace = True) 
data_project2['UacLuaenable'] = data_project2['UacLuaenable'].replace([48.0, 2.0, 49.0, 6357062.0, 3.0, 5.0, 16777216.0, 7798884.0, 255.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])

#######################################################################################################################
#                                                    NEW VARIABLES 
###############################################################################################################################



# ALSO WERE SO IMPORTANT THE GAMING CAPABILITIES AND THE PRIMARY DISK CAPACITY

###############################################################################################################################################
# NEW VARIABLES 

data_project2['DANGEROUS_RAM_INSTALLED']=data_project2[['Census_TotalPhysicalRAM']].apply(lambda x: 1 if (x['Census_TotalPhysicalRAM']<=(1024*16) and (1024*4)<x['Census_TotalPhysicalRAM'])  else 0,axis=1)

data_project2['DANGEROUS_PROCESSOR_INSTALLED']=data_project2[['filled_ProcessorCoreCount']].apply(lambda x: 1 if (x['filled_ProcessorCoreCount']<=32 and 3<x['filled_ProcessorCoreCount']) else 0,axis=1)
    
data_project2['DANGEROUS_PROCESSOR_TYPE_INSTALLED']=data_project2[['Processor']].apply(lambda x: 1 if (x['Processor']=='x64') else 0,axis=1)

data_project2['DANGEROUS_DISPLAY_SIZE']=data_project2[['Census_InternalPrimaryDiagonalDisplaySizeInInches']].apply(lambda x: 1 if (x['Census_InternalPrimaryDiagonalDisplaySizeInInches']<=60 and x['Census_InternalPrimaryDiagonalDisplaySizeInInches']>=17 ) else 0,axis=1)

data_project2['HIGH_END_COMPUTER']=data_project2[['DANGEROUS_RAM_INSTALLED','DANGEROUS_PROCESSOR_INSTALLED','DANGEROUS_DISPLAY_SIZE']].apply(lambda x: 1 if (x['DANGEROUS_RAM_INSTALLED']==1 and  x['DANGEROUS_PROCESSOR_INSTALLED']==1) else 0,axis=1)


###################################################################################################################
# SECURITY RELATED

data_project2['HAS_ONLY_ONE_AV']=data_project2[['AVProductsInstalled']].apply(lambda x: 1 if (x['AVProductsInstalled']==1 ) else 0,axis=1)


data_project2['HAS_AN_OS_WSUPPORT']=data_project2[['Platform']].apply(lambda x: 1 if (x['Platform']=='windows10' or x['Platform']=='windows8' ) else 0,axis=1)

##########################################################################################################################################################################################

#REVISION

print(data_project2.isnull().sum()/data_project2.shape[0])

print("max number of null categories caught",max(data_project2.isnull().sum()))

def print_full(df):
    pd.set_option('display.max_rows', len(df))
    print(df)
    pd.reset_option('display.max_rows')



data_project2['Census_ProcessorModelIdentifier']
data_project2['Census_PrimaryDiskTotalCapacity'] # It could be filled with the mean or the most common capacity 
data_project2['Census_SystemVolumeTotalCapacity']# This could be at much the number declare in Census_PrimaryDiskTotalCapacity. (it depends on disk total capacity and usage)
#there should be note that the amount of missings of both variables is almost the same. So the way that they are going to be filled must be similar. (they could be removed also but we removed 1% of the data)
data_project2['Census_PrimaryDiskTotalCapacity'].isnull().sum()
data_project2['Census_SystemVolumeTotalCapacity'].isnull().sum()

print(data_project2.columns[data_project2.isnull().sum()>0])

print(data_project2.columns[data_project2.isnull().sum()>0])
data_project3=data_project2.drop('Census_ProcessorCoreCount',axis=1)

print(data_project3.columns[data_project3.isnull().sum()>0])


########################################################################################################################################################################
#                                              UNIVARIATE ANALISYS                                   
########################################################################################################################################################################

# RELEASE MEMORY 
import gc
gc.collect()

# #######################################################
# # GINI AND LOGIT_TRANSFORMATION (CALLED LN)

# SEE MORE DEEP INFORMATION TO CALCULATE WOE , IV AT : http://support.sas.com/documentation/cdl/en/prochp/66704/HTML/default/viewer.htm#prochp_hpbin_details02.htm


data_project3_1=data_project3.drop('ProcessorCoreCount_4missing',axis=1)
data_project3_1.to_csv("Data_cleaned.csv")

data_project3_1[['MachineIdentifier','HasDetections','DANGEROUS_RAM_INSTALLED','DANGEROUS_PROCESSOR_INSTALLED','DANGEROUS_PROCESSOR_TYPE_INSTALLED','DANGEROUS_DISPLAY_SIZE','HIGH_END_COMPUTER', 'HAS_ONLY_ONE_AV',
       'HAS_AN_OS_WSUPPORT','Wdft_IsGamer','Census_GenuineStateName','Census_HasOpticalDiskDrive','Census_PrimaryDiskTypeName','Firewall','HasTpm','Platform','OsVer','Census_MDC2FormFactor','AVProductsEnabled','Census_TotalPhysicalRAM','filled_ProcessorCoreCount','Census_PrimaryDiskTotalCapacity','Census_InternalBatteryNumberOfCharges','Census_SystemVolumeTotalCapacity','Census_InternalPrimaryDiagonalDisplaySizeInInches','Census_InternalPrimaryDisplayResolutionHorizontal','Census_InternalPrimaryDisplayResolutionVertical']].to_csv("Data_to_model.csv")

data_project3_1_0=pd.read_csv(filepath_or_buffer="Data_to_model.csv",sep=",",low_memory=False)
data_project3_1_0.columns

data_project3_1_0.head(5)


data_project3_1.columns
titanic_1_5=data_project3_1_0#data_project3_1

titanic_1_5[['AVProductsEnabled','Census_TotalPhysicalRAM','filled_ProcessorCoreCount','Census_PrimaryDiskTotalCapacity','Census_InternalBatteryNumberOfCharges','Census_SystemVolumeTotalCapacity','Census_InternalPrimaryDiagonalDisplaySizeInInches','Census_InternalPrimaryDisplayResolutionHorizontal','Census_InternalPrimaryDisplayResolutionVertical']].info()
titanic_1_6=titanic_1_5[['AVProductsEnabled','Census_TotalPhysicalRAM','filled_ProcessorCoreCount','Census_PrimaryDiskTotalCapacity','Census_InternalBatteryNumberOfCharges','Census_SystemVolumeTotalCapacity','Census_InternalPrimaryDiagonalDisplaySizeInInches','Census_InternalPrimaryDisplayResolutionHorizontal','Census_InternalPrimaryDisplayResolutionVertical']].quantile(q=np.arange(0,1.1,0.1),axis=0)

def intervals_creator(titanic_1_6,titanic_1_5):
   result=[]
   for i in titanic_1_6.columns: 
      # print(i)
      for j in np.arange(0,(titanic_1_6[i].count()-1),1):
         if  (titanic_1_6[i].iloc[j]!=titanic_1_6[i].iloc[j+1]) :  
            # print(titanic_1_6[i].iloc[j])
            # print(titanic_1_6[i].iloc[j+1])   
            if (j!=titanic_1_6[i].count()-1):
               titanic_1_5_mod=titanic_1_5[['MachineIdentifier','HasDetections',i]][(titanic_1_5[i]<titanic_1_6[i].iloc[j+1]) & (titanic_1_5[i]>=titanic_1_6[i].iloc[j]) ].groupby(['HasDetections']).count()
            else :
               titanic_1_5_mod=titanic_1_5[['MachineIdentifier','HasDetections',i]][(titanic_1_5[i]<=titanic_1_6[i].iloc[j+1]) & (titanic_1_5[i]>=titanic_1_6[i].iloc[j]) ].groupby(['HasDetections']).count()
            # titanic_1_5_mod['MachineIdentifier'].loc[1]/titanic_1_5[['HasDetections']].sum()
            # titanic_1_5_mod['MachineIdentifier'].loc[0]/(titanic_1_5[['MachineIdentifier','HasDetections',i]].shape[0]-titanic_1_5[['HasDetections']].sum())

            result.append([i,"".join(["[",(titanic_1_6[i].iloc[j]).astype(str),"-",(titanic_1_6[i].iloc[j+1]).astype(str),")"]),(titanic_1_5_mod['MachineIdentifier'].loc[1]),(titanic_1_5_mod['MachineIdentifier'].loc[0]),(titanic_1_5_mod['MachineIdentifier'].loc[1]/titanic_1_5[['HasDetections']].sum()).astype(float)[0],(titanic_1_5_mod['MachineIdentifier'].loc[0]/(titanic_1_5[['MachineIdentifier','HasDetections',i]].shape[0]-titanic_1_5[['HasDetections']].sum())).astype(float)[0]])
   
   result1=pd.DataFrame(result)
   result1.columns=['feature','interval','count_1','count_0','Percent_1','Percent_0']
   return(result1)   


gini_table=intervals_creator(titanic_1_6,titanic_1_5)
gini_table.head(5)
gini_table.to_excel("Intervals_for_Numericals2.xlsx")


gini_calculated=[]
#i='SibSp'
for i in set(gini_table['feature']):
   print(gini_table[gini_table['feature']==i])
   gini_calculated1=[]
   gini_table_1=(gini_table[gini_table['feature']==i]['Percent_1']).agg({'Percent_1':np.cumsum})
   gini_table_0=(gini_table[gini_table['feature']==i]['Percent_0']).agg({'Percent_0':np.cumsum})
   for j in np.arange(0,(gini_table[gini_table['feature']==i].shape[0]),1):
      if (j==0):
         gini_calculated1.append((gini_table_1.iloc[j])*(gini_table_0.iloc[j]))
      else: 
         gini_calculated1.append(((gini_table_0.iloc[j]-(gini_table_0.iloc[j-1]))*((gini_table_1.iloc[j]+gini_table_1.iloc[j-1]))))
      
   gini_calculated.append([i,np.sum(gini_calculated1),abs(1-np.sum(gini_calculated1))])

gini_for_numerics=pd.DataFrame(gini_calculated)
gini_for_numerics.columns=['feature','calculation_gini','gini']

gini_for_numerics.to_excel("Gini_table_for_numericals2.xlsx")


Correlation_analysis=titanic_1_5[['AVProductsEnabled','Census_TotalPhysicalRAM','filled_ProcessorCoreCount','Census_PrimaryDiskTotalCapacity','Census_InternalBatteryNumberOfCharges','Census_SystemVolumeTotalCapacity','Census_InternalPrimaryDiagonalDisplaySizeInInches','Census_InternalPrimaryDisplayResolutionHorizontal','Census_InternalPrimaryDisplayResolutionVertical']].corr()
Correlation_analysis.to_excel("Correlation_matrix2.xlsx")

#Just 6 numeric variables survived if we use the threshold 5% of gini


gini_table['feature']
numeric_variable_selector=['Census_TotalPhysicalRAM',
'filled_ProcessorCoreCount',
'Census_PrimaryDiskTotalCapacity',
'Census_InternalBatteryNumberOfCharges',
'Census_SystemVolumeTotalCapacity',
'Census_InternalPrimaryDiagonalDisplaySizeInInches',
'Census_InternalPrimaryDisplayResolutionHorizontal']


gini_table['LN']=np.log10(gini_table['count_1']/gini_table['count_0'])
gini_table['count_1_cumsum']=gini_table[['feature','count_1']].groupby('feature').cumsum()
gini_table['count_0_cumsum']=gini_table[['feature','count_0']].groupby('feature').cumsum()
(gini_table[['feature','count_0_cumsum']].groupby('feature').max()).columns
intermediate=gini_table.groupby(['feature']).agg({'count_0':np.sum})
intermediate2=pd.merge(gini_table,intermediate,on='feature',how='left')
intermediate2_1=gini_table.groupby(['feature']).agg({'count_1':np.sum})
intermediate3=pd.merge(intermediate2,intermediate2_1,on='feature',how='left')

gini_table2=intermediate3
gini_table2.columns
gini_table2['WOE']=np.log10((gini_table2['count_0_cumsum']/gini_table2['count_0_y'])/(gini_table2['count_1_cumsum']/gini_table2['count_1_y']))
gini_table2['IV']=((gini_table2['count_0_cumsum']/gini_table2['count_0_y'])-(gini_table2['count_1_cumsum']/gini_table2['count_1_y']))*gini_table2['WOE']
gini_table2.groupby(['feature']).agg({'IV':np.sum}).sort_values(by='IV')
#the IV as the gini criteria should be modified in order to select some variablees (Select a lower threshold)
# the threshold seems to be 0.04
# THE RESULT USING IV WOULD BE

# Census_InternalPrimaryDisplayResolutionHorizontal  0.005748
# filled_ProcessorCoreCount                          0.005984
# Census_SystemVolumeTotalCapacity                   0.009062
# Census_PrimaryDiskTotalCapacity                    0.016299
# Census_InternalPrimaryDiagonalDisplaySizeInInches  0.017227
# Census_TotalPhysicalRAM 
#                            0.017405
numeric_variable_selector2=['Census_TotalPhysicalRAM',
'Census_PrimaryDiskTotalCapacity',
'Census_SystemVolumeTotalCapacity',
'filled_ProcessorCoreCount',
# 'Census_InternalPrimaryDisplayResolutionHorizontal',
'Census_InternalPrimaryDiagonalDisplaySizeInInches']




#IT MUST BE FINISHED to paste the values LN on real data
numeric_transformations=[]
result_LN=pd.DataFrame(np.array(np.zeros(data_project3_1_0.shape[0])))
for i in range(0,len(numeric_variable_selector2)):
    values_to_compare=pd.DataFrame(data_project3_1_0[numeric_variable_selector2[i]])
    intervals=gini_table2['interval'][gini_table2['feature']==numeric_variable_selector2[i]]
    Logistic_trans=gini_table2['LN'][gini_table2['feature']==numeric_variable_selector2[i]]
    for j in range(0,len(intervals)):
        if (j!=len(intervals)):
            values_to_compare[((values_to_compare>=float(intervals.iloc[j].split(sep="-")[0].split("[")[1]))  & (values_to_compare< float(intervals.iloc[j].split(sep="-")[1].split(")")[0]) ) ) ]=Logistic_trans.iloc[j]
            #values_to_compare[[numeric_variable_selector2[i]]]=values_to_compare[[numeric_variable_selector2[i]]].apply(lambda x: Logistic_trans.iloc[j] if ((x[numeric_variable_selector2[i]]>=np.float(intervals.iloc[j].split(sep="-")[0].split("[")[1]))  and (x[numeric_variable_selector2[i]]< np.float(intervals.iloc[j].split(sep="-")[1].split(")")[0]) ) ) else x[numeric_variable_selector2[i]]  , axis=1 )
        else:
            values_to_compare[((values_to_compare>=float(intervals.iloc[j].split(sep="-")[0].split("[")[1]))  & (values_to_compare<= float(intervals.iloc[j].split(sep="-")[1].split(")")[0]) ) ) ]=Logistic_trans.iloc[j]
    result_LN=values_to_compare
    numeric_transformations.append(result_LN)

#pd.concat([numeric_transformations[0],numeric_transformations[1],numeric_transformations[2]],axis=1)

data_project3_1_1=pd.concat([data_project3_1_0[['MachineIdentifier','HasDetections']],pd.concat(numeric_transformations,axis=1)],axis=1)

data_project3_1_1.head(5)






# gini_table[['feature','count_1_cumsum']].groupby('feature').max()
# gini_table.columns

# gini_table['count_1_TOTAL']

# print(gini_table)
# data_project3_1.columns


# wdf[(wdf["HasDetections"] == 1)]["HasDetections"].count().sum()
#data_project3_1["HasDetections"][data_project3_1["HasDetections"] == 1].sum()
#data_project3_1
wdf = data_project3_1_0[['HasDetections','DANGEROUS_RAM_INSTALLED','DANGEROUS_PROCESSOR_INSTALLED','DANGEROUS_PROCESSOR_TYPE_INSTALLED','DANGEROUS_DISPLAY_SIZE','HIGH_END_COMPUTER', 'HAS_ONLY_ONE_AV',
       'HAS_AN_OS_WSUPPORT','Wdft_IsGamer','Census_GenuineStateName','Census_HasOpticalDiskDrive','Census_PrimaryDiskTypeName','Firewall','HasTpm','Platform','OsVer','Census_MDC2FormFactor']]

# WOE = LN(relative_frequency_of_goods/relative_frequency_of_bads) (goods or events are the objetive of the analysis - has a malware)
# IV = SUM(NonEventsRate - EventsRate) * WOE  
# This website explains the formulas in more detail: http://rstudio-pubs-static.s3.amazonaws.com/216381_5d8fab3c7de64cb99c6f33503d6c7195.html
# Generally, the lower the IV, the less useful it is for predictive power 

# Setting up a new dataframe 
univariate = pd.DataFrame(columns =["Variable", "Category", "Count", "Event", "NonEvent", "EventRate", "NonEventRate", "logit_transformation" ,"WOE", "IV"])
A, B, C, D, E = [], [], [], [], []
ind = 0

# Applying the WOE and IV calculations 
for i in wdf.columns:
    IV = 0 
    list_variables = wdf[i].unique()
    cleanedvariableList = [x for x in list_variables if str(x) != 'nan']
    TOTALEVENT = wdf.shape[0]#wdf[(wdf["HasDetections"] == 1)]["HasDetections"].count().sum()
    for j in cleanedvariableList: 
        COUNT = wdf[(wdf[i] == j)]["HasDetections"].count().sum()
        EVENT = wdf[(wdf["HasDetections"] == 1) & (wdf[i] == j)]["HasDetections"].count().sum()
        NONEVENT = COUNT - EVENT 
        percent_EVENT = EVENT/TOTALEVENT
        percent_EVENT_relative=EVENT/(wdf[(wdf["HasDetections"] == 1)]["HasDetections"].count().sum())
        percent_NONEVENT_relative= NONEVENT / (TOTALEVENT-wdf[(wdf["HasDetections"] == 1)]["HasDetections"].count().sum())
        percent_NONEVENT = NONEVENT/TOTALEVENT
        logit_transformation = np.log10(percent_EVENT/percent_NONEVENT)
        WOE=np.log10(percent_NONEVENT_relative/percent_EVENT_relative)
        IV = (percent_NONEVENT_relative - percent_EVENT_relative)*WOE
        ind +=1
        univariate.loc[ind] = [i, j, COUNT, EVENT, NONEVENT, percent_EVENT, percent_NONEVENT,logit_transformation, WOE, IV]
#     for l in cleanedvariableList: 
#         univariate.set_value(univariate[(univariate["Category"] == l)].index[0], "IV", IV)
    
#     # setting up bins to pick good variables
#     if str(IV)  == 'inf': # for now I left out any IV that equalled to infinity (this just means that event = 0 leading to WOE = x/0 = inf)  
#         continue 
#     if IV < 0.02:#0.02
#         A.append(i)
#     elif IV <0.1: #0.1
#         B.append(i)
#     elif IV <0.3: 
#         C.append(i)
#     elif IV <0.5:
#         D.append(i)
#     else: 
#         E.append(i)

# print("Very weak prediction: \t", A, "\nWeak predictor: \t", B, "\nMedium predictor: \t", C,"\nStrong predictor: \t", D, "\nVery Strong predictor: \t", E)

univariate.groupby('Variable').agg({'IV': np.sum}).sort_values(by='IV')
# .to_excel("revision_IVS2.xlsx")



#Just pass 'HAS_ONLY_ONE_AV' using IV (based on code, I will review it in excel)
# these were too low DANGEROUS_RAM_INSTALLED', 'DANGEROUS_PROCESSOR_INSTALLED', 'DANGEROUS_PROCESSOR_TYPE_INSTALLED', 'DANGEROUS_DISPLAY_SIZE', 'HIGH_END_COMPUTER', 'HAS_AN_OS_WSUPPORT', 'Wdft_IsGamer', 'Census_GenuineStateName', 'Census_HasOpticalDiskDrive', 'Census_PrimaryDiskTypeName', 'Firewall', 'HasTpm', 'Platform'

univariate.to_excel("Revision_of_IVs.xlsx")
###########################################################################################################################################################
# if we set the IV minimal acceptance of a variable over 0.04 (0.4%) 

# HAS_ONLY_ONE_AV
# DANGEROUS_PROCESSOR_TYPE_INSTALLED
# HIGH_END_COMPUTER
# DANGEROUS_RAM_INSTALLED
# DANGEROUS_PROCESSOR_INSTALLED
# Wdft_IsGamer

categoric_variable_selector2=['HAS_ONLY_ONE_AV',
'DANGEROUS_PROCESSOR_TYPE_INSTALLED',
'HIGH_END_COMPUTER',
'DANGEROUS_RAM_INSTALLED',
'DANGEROUS_PROCESSOR_INSTALLED',
'Wdft_IsGamer',
]

categoric_transformations=[]
result_LN2=pd.DataFrame(np.array(np.zeros(data_project3_1_0.shape[0])))
for i in range(0,len(categoric_variable_selector2)):
    values_to_compare=pd.DataFrame(data_project3_1_0[categoric_variable_selector2[i]])    
    result_LN2=pd.merge(values_to_compare,univariate[['logit_transformation','Category']][univariate['Variable']==categoric_variable_selector2[i]], how='left',left_on=categoric_variable_selector2[i],right_on='Category')
    result_LN3=result_LN2.drop([categoric_variable_selector2[i],'Category'],axis=1)
    result_LN3.columns=["".join(["Logit_trans_",categoric_variable_selector2[i]])]
    categoric_transformations.append(result_LN3)





########################################################################################################################################################################################################################
#                                               FINALLY THE DATA FRAME CLEANED IN ORDER TO BE USED IN GLM WITH LOGIT_TRANSFORMATION
########################################################################################################################################################################################################################

data_project3_previous_model=pd.concat([data_project3_1_1,pd.concat(categoric_transformations,axis=1)],axis=1)
print(data_project3_previous_model)

data_project3_without_transformation=pd.concat([data_project3_1_0['MachineIdentifier'],pd.concat([data_project3_1_0[numeric_variable_selector2],data_project3_1_0[categoric_variable_selector2]],axis=1)],axis=1)

data_project3_previous_model.to_csv("data_for_modelling.csv",index=False)

###############################################################################################################################################################################################
# HERE IS WHERE YOU START PETER!!!!!!

data_project3_without_transformation.head(5)
gini_table2[gini_table2['feature']=='Census_TotalPhysicalRAM']
data_project3_previous_model.head(5)

gini_table2[gini_table2['feature']=='Census_PrimaryDiskTotalCapacity']

import gc
gc.collect()
data_project3_previous_model=pd.read_csv("data_for_modelling.csv")
data_project3_previous_model.columns[range(2,data_project3_previous_model.shape[1])]


from sklearn.model_selection import train_test_split
import statsmodels.api as sm
import statsmodels 

X_Source=data_project3_previous_model[['Census_TotalPhysicalRAM', 'Census_PrimaryDiskTotalCapacity',
       'Census_SystemVolumeTotalCapacity', 'filled_ProcessorCoreCount',
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
       'Logit_trans_HIGH_END_COMPUTER', 'Logit_trans_DANGEROUS_RAM_INSTALLED',
       'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',
       'Logit_trans_Wdft_IsGamer']]
Y_Source=data_project3_previous_model['HasDetections'].values
X_train,X_test,Y_train,Y_test=train_test_split(X_Source,Y_Source,test_size=0.3)   


print(len(Y_train))
print(len(Y_test))
# REVISAR EL COMANDO
mod1=sm.GLM(Y_train,sm.add_constant(X_train),family=sm.families.Binomial())

results=mod1.fit()

results.summary()
results.aic
results.pvalues
#DID NOT CONVERGE
import gc
gc.collect()
####################################################
#Mod2
#'filled_ProcessorCoreCount',

X_train2=X_train[['Census_TotalPhysicalRAM', 'Census_PrimaryDiskTotalCapacity',
       'Census_SystemVolumeTotalCapacity', 
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
       'Logit_trans_HIGH_END_COMPUTER', 'Logit_trans_DANGEROUS_RAM_INSTALLED',
       'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',
       'Logit_trans_Wdft_IsGamer']]

X_test2=X_test[['Census_TotalPhysicalRAM', 'Census_PrimaryDiskTotalCapacity',
       'Census_SystemVolumeTotalCapacity', 
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
       'Logit_trans_HIGH_END_COMPUTER', 'Logit_trans_DANGEROUS_RAM_INSTALLED',
       'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',
       'Logit_trans_Wdft_IsGamer']]

# Y_Source=data_project3_previous_model['HasDetections'].values
# X_train,X_test,Y_train,Y_test#=train_test_split(X_Source,Y_Source,test_size=0.3)   

mod2=sm.GLM(Y_train,sm.add_constant(X_train2),family=sm.families.Binomial())

results2=mod2.fit()

#statsmodels.genmod.generalized_linear_model.GLMResults(results2,'aic')
results2.summary()
results2.aic
results2.pvalues

# ANALYZING THE RESULTS :
# ==============================================================================
# Dep. Variable:                      y   No. Observations:              6188665
# Model:                            GLM   Df Residuals:                  6188663
# Model Family:                Binomial   Df Model:                            1
# Link Function:                  logit   Scale:                          1.0000
# Method:                          IRLS   Log-Likelihood:            -4.1710e+06
# Date:                Tue, 23 Jul 2019   Deviance:                   8.3420e+06  # HUGE DEVIANCE 
# Time:                        22:46:08   Pearson chi2:                 6.19e+06
# No. Iterations:                    15   Covariance Type:             nonrobust
# =====================================================================================================================
# ---------------------------------------------------------------------------------------------------------------------
# const                                                -0.0001      0.001     -0.173      0.863      -0.002       0.001
# Census_TotalPhysicalRAM                               1.4735      0.014    102.400      0.000       1.445       1.502
# Census_PrimaryDiskTotalCapacity                    2.647e-14   1.75e-13      0.152      0.879   -3.16e-13    3.69e-13
# Census_SystemVolumeTotalCapacity                  -2.066e-07   2.57e-06     -0.081      0.936   -5.23e-06    4.82e-06 # THE SIGN IS NOT CORRECT (THE COEFICIENT IS LOW SO IT COULD CHANGE IF ANY OTHER VARIABLE IS  REMOVED)
# Census_InternalPrimaryDiagonalDisplaySizeInInches     1.6178      0.014    117.929      0.000       1.591       1.645
# Logit_trans_HAS_ONLY_ONE_AV                           2.4373      0.006    379.896      0.000       2.425       2.450
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED        1.2132      0.015     82.024      0.000       1.184       1.242
# Logit_trans_HIGH_END_COMPUTER                         1.1161      0.048     23.224      0.000       1.022       1.210
# Logit_trans_DANGEROUS_RAM_INSTALLED                  -1.2599      0.049    -25.511      0.000      -1.357      -1.163 # THE SIGN IS NOT CORRECT (IT WILL CAUSE A PROBLEM TO THE MODEL)
# Logit_trans_DANGEROUS_PROCESSOR_INSTALLED             0.5333      0.021     25.355      0.000       0.492       0.575
# Logit_trans_Wdft_IsGamer                              1.8693      0.018    101.421      0.000       1.833       1.905
# =====================================================================================================================

# >>> results2.aic
# 8341971.464604879
#Pvalues
# const                                                 8.625892e-01
# Census_TotalPhysicalRAM                               0.000000e+00
# Census_PrimaryDiskTotalCapacity                       8.794896e-01
# Census_SystemVolumeTotalCapacity                      9.358223e-01 # SHOULD BE ELIMINATED TOO HIGH P VALUE
# Census_InternalPrimaryDiagonalDisplaySizeInInches     0.000000e+00
# Logit_trans_HAS_ONLY_ONE_AV                           0.000000e+00
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED        0.000000e+00
# Logit_trans_HIGH_END_COMPUTER                        2.627612e-119
# Logit_trans_DANGEROUS_RAM_INSTALLED                  1.500234e-143
# Logit_trans_DANGEROUS_PROCESSOR_INSTALLED            8.007100e-142
# Logit_trans_Wdft_IsGamer                              0.000000e+00

import gc
gc.collect()

####################################################
#Mod3
#'filled_ProcessorCoreCount','Census_SystemVolumeTotalCapacity', 
X_train3=X_train[['Logit_trans_DANGEROUS_RAM_INSTALLED',
       'Census_TotalPhysicalRAM', 'Census_PrimaryDiskTotalCapacity',
        
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
       'Logit_trans_HIGH_END_COMPUTER',
       'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',
       'Logit_trans_Wdft_IsGamer']]

X_test3=X_test[['Logit_trans_DANGEROUS_RAM_INSTALLED',
       'Census_TotalPhysicalRAM', 'Census_PrimaryDiskTotalCapacity',
       
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
       'Logit_trans_HIGH_END_COMPUTER', 
       'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',
       'Logit_trans_Wdft_IsGamer']]
# X_train,X_test,Y_train,Y_test=train_test_split(X_Source,Y_Source,test_size=0.3)   

mod3=sm.GLM(Y_train,sm.add_constant(X_train3),family=sm.families.Binomial())

results3=mod3.fit()

results3.summary()

results3.aic
results3.pvalues

#                Generalized Linear Model Regression Results
# ==============================================================================
# Dep. Variable:                      y   No. Observations:              6188665
# Model:                            GLM   Df Residuals:                  6188664
# Model Family:                Binomial   Df Model:                            0
# Link Function:                  logit   Scale:                          1.0000
# Method:                          IRLS   Log-Likelihood:            -4.1710e+06
# Date:                Tue, 23 Jul 2019   Deviance:                   8.3420e+06
# Time:                        23:03:40   Pearson chi2:                 6.19e+06
# No. Iterations:                     6   Covariance Type:             nonrobust
# =====================================================================================================================
#                                                         coef    std err          z      P>|z|      [0.025      0.975]
# ---------------------------------------------------------------------------------------------------------------------
# const                                                -0.0001      0.001     -0.174      0.862      -0.002       0.001
# Logit_trans_DANGEROUS_RAM_INSTALLED                  -1.2599      0.049    -25.511      0.000      -1.357      -1.163 BESIDES THIS VARIABLE IS BEHAVING WELL IT WILL BE ELIMINATED IN FUTURE STEPS
# Census_TotalPhysicalRAM                               1.4735      0.014    102.400      0.000       1.445       1.502
# Census_PrimaryDiskTotalCapacity                    2.634e-14   1.75e-13      0.151      0.880   -3.16e-13    3.68e-13
# Census_InternalPrimaryDiagonalDisplaySizeInInches     1.6178      0.014    117.929      0.000       1.591       1.645
# Logit_trans_HAS_ONLY_ONE_AV                           2.4373      0.006    379.896      0.000       2.425       2.450
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED        1.2132      0.015     82.024      0.000       1.184       1.242
# Logit_trans_HIGH_END_COMPUTER                         1.1161      0.048     23.223      0.000       1.022       1.210
# Logit_trans_DANGEROUS_PROCESSOR_INSTALLED             0.5333      0.021     25.355      0.000       0.492       0.575
# Logit_trans_Wdft_IsGamer                              1.8693      0.018    101.421      0.000       1.833       1.905
# =====================================================================================================================
# """
# >>> results3.aic
# 8341971.10127041 DIMINISH AS EXPECTED 
# >>> results3.pvalues
# const                                                 8.622332e-01
# Logit_trans_DANGEROUS_RAM_INSTALLED                  1.501426e-143
# Census_TotalPhysicalRAM                               0.000000e+00
# Census_PrimaryDiskTotalCapacity                       8.800771e-01 NEXT ELIMINATION
# Census_InternalPrimaryDiagonalDisplaySizeInInches     0.000000e+00
# Logit_trans_HAS_ONLY_ONE_AV                           0.000000e+00
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED        0.000000e+00
# Logit_trans_HIGH_END_COMPUTER                        2.639889e-119
# Logit_trans_DANGEROUS_PROCESSOR_INSTALLED            7.993567e-142
# Logit_trans_Wdft_IsGamer                              0.000000e+00

import gc
gc.collect()


#  THE CONFIDENCE INTERVAL OF THE VARIABLES (THE HIGHER WHICH SURPASS THE 0) IS THE DANGEROUS RAM
####################################################
#Mod4
#'filled_ProcessorCoreCount','Census_SystemVolumeTotalCapacity', , 'Census_PrimaryDiskTotalCapacity',
X_train4=X_train[['Logit_trans_DANGEROUS_RAM_INSTALLED',
       'Census_TotalPhysicalRAM',
        
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
       'Logit_trans_HIGH_END_COMPUTER',
       'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',
       'Logit_trans_Wdft_IsGamer']]

X_test4=X_test[['Logit_trans_DANGEROUS_RAM_INSTALLED',
       'Census_TotalPhysicalRAM', 
       
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
       'Logit_trans_HIGH_END_COMPUTER', 
       'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',
       'Logit_trans_Wdft_IsGamer']]
# X_train,X_test,Y_train,Y_test=train_test_split(X_Source,Y_Source,test_size=0.3)   

mod4=sm.GLM(Y_train,sm.add_constant(X_train4),family=sm.families.Binomial())

results4=mod4.fit()

results4.summary()

results4.aic
results4.pvalues

#                  Generalized Linear Model Regression Results
# ==============================================================================
# Dep. Variable:                      y   No. Observations:              6188665
# Model:                            GLM   Df Residuals:                  6188656
# Model Family:                Binomial   Df Model:                            8
# Link Function:                  logit   Scale:                          1.0000
# Method:                          IRLS   Log-Likelihood:            -4.1710e+06
# Date:                Tue, 23 Jul 2019   Deviance:                   8.3420e+06
# Time:                        23:10:09   Pearson chi2:                 6.19e+06
# No. Iterations:                     5   Covariance Type:             nonrobust
# =====================================================================================================================
#                                                         coef    std err          z      P>|z|      [0.025      0.975]
# ---------------------------------------------------------------------------------------------------------------------
# const                                                -0.0001      0.001     -0.173      0.862      -0.002       0.001
# Logit_trans_DANGEROUS_RAM_INSTALLED                  -1.2599      0.049    -25.510      0.000      -1.357      -1.163 will be eliminated now
# Census_TotalPhysicalRAM                               1.4735      0.014    102.400      0.000       1.445       1.502
# Census_InternalPrimaryDiagonalDisplaySizeInInches     1.6178      0.014    117.929      0.000       1.591       1.645
# Logit_trans_HAS_ONLY_ONE_AV                           2.4373      0.006    379.896      0.000       2.425       2.450
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED        1.2132      0.015     82.024      0.000       1.184       1.242
# Logit_trans_HIGH_END_COMPUTER                         1.1161      0.048     23.223      0.000       1.022       1.210
# Logit_trans_DANGEROUS_PROCESSOR_INSTALLED             0.5333      0.021     25.355      0.000       0.492       0.575
# Logit_trans_Wdft_IsGamer                              1.8693      0.018    101.421      0.000       1.833       1.905
# =====================================================================================================================
# """
# >>> results4.aic
# 8341987.124100515 IT raised UP but the Pvalue for the last variable was too high
# >>> results4.pvalues
# const                                                 8.623004e-01
# Logit_trans_DANGEROUS_RAM_INSTALLED                  1.510326e-143
# Census_TotalPhysicalRAM                               0.000000e+00
# Census_InternalPrimaryDiagonalDisplaySizeInInches     0.000000e+00
# Logit_trans_HAS_ONLY_ONE_AV                           0.000000e+00
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED        0.000000e+00
# Logit_trans_HIGH_END_COMPUTER                        2.654475e-119
# Logit_trans_DANGEROUS_PROCESSOR_INSTALLED            7.982719e-142
# Logit_trans_Wdft_IsGamer                              0.000000e+00

import gc
gc.collect()


#  THE CONFIDENCE INTERVAL OF THE VARIABLES (THE HIGHER WHICH SURPASS THE 0) IS THE DANGEROUS RAM
####################################################
#Mod5
#'filled_ProcessorCoreCount','Census_SystemVolumeTotalCapacity', , 'Census_PrimaryDiskTotalCapacity','Logit_trans_DANGEROUS_RAM_INSTALLED',

X_train5=X_train[[
       'Census_TotalPhysicalRAM',
        
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
       'Logit_trans_HIGH_END_COMPUTER',
       'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',
       'Logit_trans_Wdft_IsGamer']]

X_test5=X_test[[
       'Census_TotalPhysicalRAM', 
       
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
       'Logit_trans_HIGH_END_COMPUTER', 
       'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',
       'Logit_trans_Wdft_IsGamer']]
# X_train,X_test,Y_train,Y_test=train_test_split(X_Source,Y_Source,test_size=0.3)   

mod5=sm.GLM(Y_train,sm.add_constant(X_train5),family=sm.families.Binomial())

results5=mod5.fit()

results5.summary()
results5.aic
results5.pvalues
#                  Generalized Linear Model Regression Results
# ==============================================================================
# Dep. Variable:                      y   No. Observations:              6188665
# Model:                            GLM   Df Residuals:                  6188657
# Model Family:                Binomial   Df Model:                            7
# Link Function:                  logit   Scale:                          1.0000
# Method:                          IRLS   Log-Likelihood:            -4.1713e+06
# Date:                Tue, 23 Jul 2019   Deviance:                   8.3426e+06
# Time:                        23:25:54   Pearson chi2:                 6.19e+06
# No. Iterations:                     5   Covariance Type:             nonrobust
# =====================================================================================================================
#                                                         coef    std err          z      P>|z|      [0.025      0.975]
# ---------------------------------------------------------------------------------------------------------------------
# const                                                -0.0002      0.001     -0.205      0.838      -0.002       0.001
# Census_TotalPhysicalRAM                               1.3806      0.014     99.312      0.000       1.353       1.408
# Census_InternalPrimaryDiagonalDisplaySizeInInches     1.6239      0.014    118.400      0.000       1.597       1.651
# Logit_trans_HAS_ONLY_ONE_AV                           2.4334      0.006    379.413      0.000       2.421       2.446
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED        1.2310      0.015     83.322      0.000       1.202       1.260
# Logit_trans_HIGH_END_COMPUTER                        -0.0181      0.018     -0.991      0.322      -0.054       0.018 IT WILL BE ELIMINATED BY THE CONFIDENCE INTERVAL SO PVALUE AND COEFICIENT
# Logit_trans_DANGEROUS_PROCESSOR_INSTALLED             0.6835      0.020     33.853      0.000       0.644       0.723
# Logit_trans_Wdft_IsGamer                              1.8671      0.018    101.306      0.000       1.831       1.903
# =====================================================================================================================
# """
# >>> results5.aic
# 8342636.229299461
# >>> results5.pvalues
# const                                                 8.379059e-01
# Census_TotalPhysicalRAM                               0.000000e+00
# Census_InternalPrimaryDiagonalDisplaySizeInInches     0.000000e+00
# Logit_trans_HAS_ONLY_ONE_AV                           0.000000e+00
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED        0.000000e+00
# Logit_trans_HIGH_END_COMPUTER                         3.218274e-01
# Logit_trans_DANGEROUS_PROCESSOR_INSTALLED            3.294257e-251
# Logit_trans_Wdft_IsGamer                              0.000000e+00


####################################################
#Mod6

#'filled_ProcessorCoreCount','Census_SystemVolumeTotalCapacity', , 'Census_PrimaryDiskTotalCapacity','Logit_trans_DANGEROUS_RAM_INSTALLED','Logit_trans_HIGH_END_COMPUTER', 


X_train6=X_train[[
       'Census_TotalPhysicalRAM',
        
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
      
       'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',
       'Logit_trans_Wdft_IsGamer']]

X_test6=X_test[[
       'Census_TotalPhysicalRAM', 
       
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
       
       'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',
       'Logit_trans_Wdft_IsGamer']]

mod6=sm.GLM(Y_train,sm.add_constant(X_train6),family=sm.families.Binomial())

results6=mod6.fit()

results6.summary()
results6.aic
results6.pvalues



#                  Generalized Linear Model Regression Results
# ==============================================================================
# Dep. Variable:                      y   No. Observations:              6188665
# Model:                            GLM   Df Residuals:                  6188658
# Model Family:                Binomial   Df Model:                            6
# Link Function:                  logit   Scale:                          1.0000
# Method:                          IRLS   Log-Likelihood:            -4.1713e+06
# Date:                Tue, 23 Jul 2019   Deviance:                   8.3426e+06
# Time:                        23:27:55   Pearson chi2:                 6.19e+06
# No. Iterations:                     5   Covariance Type:             nonrobust
# =====================================================================================================================
#                                                         coef    std err          z      P>|z|      [0.025      0.975]
# ---------------------------------------------------------------------------------------------------------------------
# const                                                -0.0002      0.001     -0.203      0.839      -0.002       0.001
# Census_TotalPhysicalRAM                               1.3738      0.012    113.543      0.000       1.350       1.398
# Census_InternalPrimaryDiagonalDisplaySizeInInches     1.6239      0.014    118.399      0.000       1.597       1.651
# Logit_trans_HAS_ONLY_ONE_AV                           2.4332      0.006    379.699      0.000       2.421       2.446
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED        1.2325      0.015     83.839      0.000       1.204       1.261
# Logit_trans_DANGEROUS_PROCESSOR_INSTALLED             0.6780      0.019     34.919      0.000       0.640       0.716
# Logit_trans_Wdft_IsGamer                              1.8657      0.018    101.502      0.000       1.830       1.902
# =====================================================================================================================
# """
# >>> results6.aic
# 8342635.210828552  AGAIN IT DIMINISH AS WE EXPECT
# >>> results6.pvalues
# const                                                 8.391111e-01
# Census_TotalPhysicalRAM                               0.000000e+00
# Census_InternalPrimaryDiagonalDisplaySizeInInches     0.000000e+00
# Logit_trans_HAS_ONLY_ONE_AV                           0.000000e+00
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED        0.000000e+00
# Logit_trans_DANGEROUS_PROCESSOR_INSTALLED            3.867521e-267  #VERY LOW , WE CAN TRY REMOVING IT TO SEE HOW IT MOVES
# Logit_trans_Wdft_IsGamer                              0.000000e+00
####################################################

#'filled_ProcessorCoreCount','Census_SystemVolumeTotalCapacity', , 'Census_PrimaryDiskTotalCapacity','Logit_trans_DANGEROUS_RAM_INSTALLED','Logit_trans_HIGH_END_COMPUTER', 'Logit_trans_DANGEROUS_PROCESSOR_INSTALLED',

X_train7=X_train[[
       'Census_TotalPhysicalRAM',
        
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
      
       
       'Logit_trans_Wdft_IsGamer']]

X_test7=X_test[[
       'Census_TotalPhysicalRAM', 
       
       'Census_InternalPrimaryDiagonalDisplaySizeInInches',
       'Logit_trans_HAS_ONLY_ONE_AV',
       'Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED',
       
       
       'Logit_trans_Wdft_IsGamer']]
# X_train,X_test,Y_train,Y_test=train_test_split(X_Source,Y_Source,test_size=0.3)   

mod7=sm.GLM(Y_train,sm.add_constant(X_train7),family=sm.families.Binomial())

results7=mod7.fit()

results7.summary()

results7.aic
results7.pvalues


#                  Generalized Linear Model Regression Results
# ==============================================================================
# Dep. Variable:                      y   No. Observations:              6188665
# Model:                            GLM   Df Residuals:                  6188659
# Model Family:                Binomial   Df Model:                            5
# Link Function:                  logit   Scale:                          1.0000
# Method:                          IRLS   Log-Likelihood:            -4.1719e+06
# Date:                Tue, 23 Jul 2019   Deviance:                   8.3438e+06
# Time:                        23:31:17   Pearson chi2:                 6.19e+06
# No. Iterations:                     5   Covariance Type:             nonrobust
# =====================================================================================================================
#                                                         coef    std err          z      P>|z|      [0.025      0.975]
# ---------------------------------------------------------------------------------------------------------------------
# const                                                -0.0001      0.001     -0.122      0.903      -0.002       0.002
# Census_TotalPhysicalRAM                               1.5364      0.011    137.374      0.000       1.514       1.558
# Census_InternalPrimaryDiagonalDisplaySizeInInches     1.5744      0.014    115.424      0.000       1.548       1.601
# Logit_trans_HAS_ONLY_ONE_AV                           2.4405      0.006    381.093      0.000       2.428       2.453
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED        1.2167      0.015     82.826      0.000       1.188       1.245
# Logit_trans_Wdft_IsGamer                              1.8855      0.018    102.635      0.000       1.850       1.922
# =====================================================================================================================
# """
# >>> results7.aic
# 8343852.219753938    AS IT DOES NOT DIMINISH , WE COULD SAY THE PREVIOUS MODEL WAS BETTER (MOD6 is the bestM GLM)
# >>> results7.pvalues
# const                                                0.902761
# Census_TotalPhysicalRAM                              0.000000
# Census_InternalPrimaryDiagonalDisplaySizeInInches    0.000000
# Logit_trans_HAS_ONLY_ONE_AV                          0.000000
# Logit_trans_DANGEROUS_PROCESSOR_TYPE_INSTALLED       0.000000
# Logit_trans_Wdft_IsGamer                             0.000000
#####################################################################################################################################


mod6_prediction=results6.predict(sm.add_constant(X_train6))

mod6_prediction

########################################################################################################################################

# IN HERE WE CAN MODEL THE PROBABILITY TO HAVE A MALWARE AS (SIGMOID FUNCTION):

# 1/1+e(-y)

# WHERE y is the linear combination of atributes we study

# SO THE PROBABILITY TO HAVE A MALWARE FOR EACH SUBJECT WILL BE

Likelihood_malware=(1+np.exp((-1)*mod6_prediction))**(-1)
Likelihood_malware
Likelihood_malware.index

Likelihood_malware1=pd.DataFrame(Likelihood_malware)
Data_to_be_proved=pd.DataFrame(Y_train)
Data_to_be_proved.index=Likelihood_malware1.index
positions=pd.DataFrame(Likelihood_malware1.index)
positions.index=Likelihood_malware1.index
data_to_gini=pd.concat([pd.concat([Likelihood_malware1,Data_to_be_proved],axis=1),positions],axis=1)

data_to_gini.columns=['Predicted','HasDetections','MachineIdentifier']

#titanic_1_6=data_to_gini[['Predicted']].quantile(q=np.arange(0,1.1,0.1),axis=0)
#titanic_1_5=data_to_gini
studio_pred_gini=intervals_creator(data_to_gini[['Predicted']].quantile(q=np.arange(0,1.1,0.1),axis=0),data_to_gini)

from  matplotlib  import pyplot as plt
plt.plot(studio_pred_gini['count_1'])
plt.plot(studio_pred_gini['count_0'])
plt.show()


#The interval for goods is until 0.63568416895761.99999 
# the interval for bads is from 0.63568416895762



mod6_prediction_on_test=results6.predict(sm.add_constant(X_test6))

mod6_prediction_on_test
Likelihood_malware_test=pd.DataFrame((1+np.exp((-1)*mod6_prediction_on_test))**(-1))
Likelihood_malware_test.head(5)
Likelihood_malware_test.columns=['Predicted']
Likelihood_malware_test['Binary_response']=Likelihood_malware_test[['Predicted']].apply(lambda x: 1 if x['Predicted']>=0.63568416895762 else 0 ,axis=1)

from sklearn import metrics

accuracy_GLM=metrics.accuracy_score(Y_test,Likelihood_malware_test['Binary_response'])
# 0.568705097679925
Predicted_corretly=accuracy_GLM*len(Y_test)
misclassified=len(Y_test)-Predicted_corretly
conf_matrix=metrics.confusion_matrix(Y_test,Likelihood_malware_test['Binary_response'],labels=[1,0])

print(conf_matrix)
# [[558751 768818]
#  [375099 949617]]
#It performs better on goods than bads

############################################################################################
####### USING SVM (I WILL PROVE)

# from sklearn.svm import SVC

# # svm_clf = SVC(kernel = 'linear', C=1)
# # svm_result = svm_clf.fit(X_train6, Y_train)

# print(X_train6.describe())

# svm_clf2 = SVC(kernel = 'sigmoid', C=1)
# svm_result_sigmoid = svm_clf2.fit(X_train6, Y_train)
# metrics.accuracy_score(svm_result_sigmoid.predict)
# svm_result_sigmoid.



############################################################################################
####### USING MLP (MULTILAYER PERCEPTRON) NEURAL NETWORK

X_train6.describe()
from sklearn.neural_network import MLPClassifier
clf = MLPClassifier(solver='adam', alpha=1e-5,  hidden_layer_sizes=(5, 2), random_state=1)
clf.fit(X_train6, Y_train)
clf.score(X_test6,Y_test)

#0.5875326369526653

from sklearn.neural_network import MLPClassifier
from sklearn import metrics

clf = MLPClassifier(activation='logistic',solver='adam', alpha=1e-5,  hidden_layer_sizes=(5, 2), random_state=1)
clf.fit(X_train6, Y_train)
clf.score(X_test6,Y_test)
#0.5868871557920812
prediction_using_MLP=clf.predict(X_test6)

prediction_using_MLP
conf_matrix_MLP=metrics.confusion_matrix(Y_test,prediction_using_MLP,labels=[1,0])
conf_matrix_MLP
conf_matrix_MLP=metrics.confusion_matrix(Y_test,prediction_using_MLP,labels=[0,1])


from sklearn.neural_network import MLPClassifier
clf2 = MLPClassifier(activation='logistic',solver='adam', alpha=1e-5,  hidden_layer_sizes=(3,2), random_state=1)
clf2.fit(X_train6, Y_train)
clf2.score(X_test6,Y_test)
#0.5873904953653171
prediction2_using_MLP=clf2.predict(X_test6)
conf_matrix_MLP2=metrics.confusion_matrix(Y_test,prediction2_using_MLP,labels=[0,1])

# from sklearn.neural_network import MLPClassifier
# clf3 = MLPClassifier(activation='logistic',solver='adam', alpha=1e-5,  hidden_layer_sizes=(2), random_state=1)
# clf3.fit(X_train6, Y_train)
# clf3.score(X_test6,Y_test)
# #0.5870089375764671
# prediction3_using_MLP=clf3.predict(X_test6)
#conf_matrix3_MLP=metrics.confusion_matrix(Y_test,prediction3_using_MLP,labels=[0,1])


